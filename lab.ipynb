{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3254337",
   "metadata": {},
   "source": [
    "# Lab 1: KNN for handwritten digits recognition \n",
    "\n",
    "**Course:** Introduction to AI (Spring 2025/2026)  \n",
    "**Instructor:** Yurii Hannich  \n",
    "**Points:** 6  \n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ Goals\n",
    "\n",
    "In this lab, you will work with the classic **MNIST** dataset (handwritten digits). Unlike Lab 0 (Iris), where we had high-level features (petal length, etc.), here we work with **raw pixels**.\n",
    "\n",
    "You will:\n",
    "1.  **Explore the data**: Understand how images are represented as vectors (Flattening).\n",
    "2.  **Normalize data**: Implement simple scaling and understand why it helps distance-based algorithms.\n",
    "3.  **Visualise high-dimensional data**: Use unsupervised learning algorithm UMAP for dimensionality reduction to see how 784-dimensional data looks in 2D.\n",
    "4.  **Train KNN**: Build a classifier for handwritten digits.\n",
    "5.  **Look inside the box**: Visualize the actual \"neighbors\" the model uses to make decisions.\n",
    "6.  **Break the model**: Test how robust the model is to simple pixel shifts.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1278f7b1-6bd3-42a6-9426-29636829b89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install numpy matplotlib scikit-learn umap-learn torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7631add",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a927ff",
   "metadata": {},
   "source": [
    "## Part 1: Data Loading & Exploration\n",
    "\n",
    "### 1.1 Loading MNIST with Torchvision\n",
    "The MNIST dataset consists of 70,000 images of handwritten digits (0-9). Each image is **28x28** pixels.\n",
    "We will use `torchvision` to download the data locally.\n",
    "\n",
    "*Note: The first run might take a minute to download.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4b85b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Downloading MNIST...\")\n",
    "\n",
    "# Download Training Data\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=None)\n",
    "# Download Test Data\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=None)\n",
    "\n",
    "# Extract data as numpy arrays\n",
    "# X is the image data (N, 28, 28), y is the label (N,)\n",
    "X_train_raw = train_dataset.data.numpy()\n",
    "y_train = train_dataset.targets.numpy()\n",
    "\n",
    "X_test_raw = test_dataset.data.numpy()\n",
    "y_test = test_dataset.targets.numpy()\n",
    "\n",
    "print(f\"Train X Shape: {X_train_raw.shape}\")\n",
    "print(f\"Test X Shape:  {X_test_raw.shape}\")\n",
    "print(f\"Train y Shape: {y_train.shape}\")\n",
    "print(f\"Test y Shape:  {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbeba97",
   "metadata": {},
   "source": [
    "### 1.2 Visualizing Raw Data\n",
    "As you can see, we have 2D matrices `(28, 28)` objects in our dataset instead of just vectors (rows). Let's visualize first image to see what we are working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e287945-5154-4ce8-8fe4-c7fc25b4d7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_raw[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a1b694-d183-4de1-80d0-3f03da6e821b",
   "metadata": {},
   "source": [
    "Not the best view.\n",
    "\n",
    "So lets use matplotlib for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3cd1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot first 5 images\n",
    "fig, axes = plt.subplots(1, 5, figsize=(10, 3))\n",
    "for i in range(5):\n",
    "    axes[i].imshow(X_train_raw[i], cmap='gray')\n",
    "    axes[i].set_title(f\"Label: {y_train[i]}\")\n",
    "    axes[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0503b5b2-480c-4994-9a9f-b858a0d40cf7",
   "metadata": {},
   "source": [
    "And what about our target?\n",
    "\n",
    "Let's check it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ab042e-3092-4850-aa4e-11c4cec4b446",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.bincount(y_train)\n",
    "\n",
    "plt.bar(\n",
    "    np.arange(counts.shape[0]).astype(str), \n",
    "    counts\n",
    ")\n",
    "\n",
    "plt.xlabel('Class label - Digit')\n",
    "plt.ylabel('Count of images in train set')\n",
    "plt.title('Class distribution in train set')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf29ee9f-3c76-4d94-a969-9b96160ba717",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ðŸ¤” Questions to think about\n",
    "\n",
    "Before we continue, let's think about what we're dealing with:\n",
    "\n",
    "1. **What are features in our dataset and what is the dimensionality of the feature space?**  \n",
    "\n",
    "2. **Is this a classification or regression task?**  \n",
    "\n",
    "3. **How many classes do we need to predict?**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c0b896",
   "metadata": {},
   "source": [
    "## Part 2: Preprocessing\n",
    "\n",
    "### 2.1 Task 1: Flattening (Forward Reshape) - 1 point\n",
    "Machine Learning models (like KNN or SVM) typically expect a **feature vector** for each sample, not a 2D matrix. So, we need to convert our images from shape `(N, 28, 28)` to `(N, 784)` as\n",
    "$28 \\times 28 = 784$.\n",
    "\n",
    "**Task 1:** Implement a function to flatten the image batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a739fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_images(X_2d):\n",
    "    \"\"\"\n",
    "    Converts a batch of images from (N, 28, 28) to (N, 784).\n",
    "    \"\"\"\n",
    "    # N is the number of samples (e.g. 60000)\n",
    "    N = X_2d.shape[0]\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    # Use .reshape() method for arrays from numpy to change dimensions\n",
    "    X_flat = ...\n",
    "\n",
    "    return X_flat\n",
    "\n",
    "X_train_flat = flatten_images(X_train_raw)\n",
    "X_test_flat = flatten_images(X_test_raw)\n",
    "\n",
    "if X_train_flat is not None:\n",
    "    print(f\"Original shape: {X_train_raw.shape}\")\n",
    "    print(f\"Flattened shape: {X_train_flat.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac4709f-04ef-423e-b5c4-374bc121c666",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "**Expected results**:\n",
    "```\n",
    "Original shape: (60000, 28, 28)\n",
    "Flattened shape: (60000, 784)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe97ecb",
   "metadata": {},
   "source": [
    "### 2.2 Task 2: Feature Scaling (Normalization) - 1 point\n",
    "\n",
    "#### 2.2.1 Why do we need scaling?\n",
    "\n",
    "Machine Learning algorithms, especially those based on **distance** (like KNN, K-Means, or SVMs), are very sensitive to the scale of the data.\n",
    "\n",
    "Imagine a dataset with two features:\n",
    "\n",
    "1. **Age:** 20 to 80 years.\n",
    "2. **Salary:** 10,000 to 200,000 dollars.\n",
    "\n",
    "When KNN calculates the **Euclidean Distance** between two people:\n",
    "$$d(p, q) = \\sqrt{(Age_1 - Age_2)^2 + (Salary_1 - Salary_2)^2}$$\n",
    "\n",
    "A small difference in Salary (e.g., $1000) will square to 1,000,000.\n",
    "\n",
    "A large difference in Age (e.g., 50 years) will square to only 2,500.\n",
    "\n",
    "**The Result:** The algorithm will completely ignore \"Age\" because \"Salary\" numbers are just bigger. The model becomes biased toward features with larger magnitudes.\n",
    "\n",
    "To fix this, we bring all features to the same scale. We move **from absolute values of feature - to it's variance**, and actually, the **variance is a fuel for ML**.\n",
    "\n",
    "#### 2.2.2 Common Types of Scaling\n",
    "\n",
    "There are two main techniques used in Data Science:\n",
    "\n",
    "##### 1. Min-Max Scaling (Normalization)\n",
    "\n",
    "This transforms features to fit within a specific range, usually **[0, 1]**.\n",
    "\n",
    "$$X_{norm} = \\frac{X - X_{min}}{X_{max} - X_{min}}$$\n",
    "\n",
    "##### 2. Standardization (Z-Score Normalization)\n",
    "\n",
    "This transforms data so that it has a **mean ($\\mu$) of 0** and a **standard deviation ($\\sigma$) of 1**. This is the most common type of normalization.\n",
    "\n",
    "$$Z = \\frac{X - \\mu}{\\sigma}$$\n",
    "\n",
    "#### 2.2.3 What we use for Images\n",
    "\n",
    "Digital images consists of pixels. In a grayscale image (like MNIST), every pixel is an integer between **0 (black)** and **255 (white)**.\n",
    "\n",
    "Since the minimum and maximum values are fixed and known ($min=0, max=255$), **Min-Max Scaling** is the standard approach for image data.\n",
    "\n",
    "The formula simplifies significantly:\n",
    "$$X_{norm} = \\frac{X - 0}{255 - 0} = \\frac{X}{255}$$\n",
    "\n",
    "**Task 2:** Implement this simple normalization in the cell below to convert our pixel values from integers [0, 255] to floats [0.0, 1.0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6284ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(X):\n",
    "    \"\"\"\n",
    "    Scales input X from [0, 255] to [0, 1].\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # Ensure the result is float, not integer\n",
    "    X_norm = ... \n",
    "\n",
    "    return X_norm\n",
    "\n",
    "X_train = normalize_data(X_train_flat)\n",
    "X_test = normalize_data(X_test_flat)\n",
    "\n",
    "if X_train is not None:\n",
    "    print(f\"Max value before: {X_train_flat.max()}\")\n",
    "    print(f\"Max value after:  {X_train.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eedda25-5cc3-4a67-9ee9-f703f040fffa",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "**Expected results**:\n",
    "```\n",
    "Max value before: 255\n",
    "Max value after:  1.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab46c6a",
   "metadata": {},
   "source": [
    "## Part 3: Dimensionality Reduction (UMAP)\n",
    "\n",
    "We now have vectors of size 784. It's impossible for humans to imagine 784-dimensional space.\n",
    "**UMAP** is a technique to project this high-dimensional data into 2D while preserving clusters (similar digits stay together)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d89fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "# Use a subset of 5000 images for speed\n",
    "print(\"Running UMAP... (This may take ~60 seconds)\")\n",
    "\n",
    "if X_train is not None:\n",
    "    reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)\n",
    "    embedding = reducer.fit_transform(X_train[:5000])\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = plt.scatter(embedding[:, 0], embedding[:, 1], c=y_train[:5000], cmap='Spectral', s=5)\n",
    "    plt.colorbar(scatter, boundaries=np.arange(11)-0.5).set_ticks(np.arange(10))\n",
    "    plt.title('UMAP projection of MNIST', fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4bf662-b028-4a6a-a2e5-edf5ec6fb970",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ðŸ¤” Questions to think about\n",
    "\n",
    "Before we continue, let's think about what we're dealing with:\n",
    "\n",
    "1. **What is dimensionality of the feature space now?**  \n",
    "\n",
    "2. **Can we run KNN in this, reduced space**  \n",
    "\n",
    "3. **Look at the close clusters. Do the digits of them really ma look similar?**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744ac974",
   "metadata": {},
   "source": [
    "## Part 4: K-Nearest Neighbors\n",
    "\n",
    "After all the preparation is done - let's classify images using KNN on the **flattened vectors**. Using reduced UMAP-projected is a real option, but in context of this lab we'll make classification in original 784D space.\n",
    "\n",
    "**Important:** KNN is a \"Lazy Learner\". It compares the test image to **every** training image (actually there're more optimized versions of KNN that learn some graph structure for faster navigation during inference, but 'vanilla' KNN doesn't do this). \n",
    "To save time during this lab, we will use a **subset** of the training data (10,000 samples).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783fb055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a smaller subset for speed (10k train, 1k test)\n",
    "train_limit = 10000\n",
    "test_limit = 1000\n",
    "\n",
    "X_train_sub = X_train[:train_limit]\n",
    "y_train_sub = y_train[:train_limit]\n",
    "\n",
    "X_test_sub = X_test[:test_limit]\n",
    "y_test_sub = y_test[:test_limit]\n",
    "\n",
    "print(f\"Training on {len(X_train_sub)} samples\")\n",
    "print(f\"Testing on {len(y_test_sub)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d985442-81fa-4a6e-bc58-91e4eeb9a71c",
   "metadata": {},
   "source": [
    "### 4.1 **Task 3:** Implement the training, prediction and evaluation pipeline - 2 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80c4e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(X_train, y_train, X_test, y_test, k=3):\n",
    "    \"\"\"\n",
    "    1. Initialize KNN classifier with n_neighbors=k\n",
    "    2. Fit on X_train, y_train\n",
    "    3. Predict X_test\n",
    "    4. Calculate and return accuracy score\n",
    "    \"\"\"\n",
    "    model = None\n",
    "    train_accuracy = 0.0\n",
    "    test_accuracy = 0.0\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    # model = KNeighborsClassifier(...)\n",
    "    # model.fit(...)\n",
    "    \n",
    "    # train_preds = model.predict(...)\n",
    "    # train_accuracy = accuracy_score(...)\n",
    "    # test_preds = model.predict(...)\n",
    "    # test_accuracy = accuracy_score(...)\n",
    "    \n",
    "    return model, train_accuracy, test_accuracy\n",
    "\n",
    "if X_train is not None:\n",
    "    knn_model, acc_train, acc_test = train_and_evaluate(X_train_sub, y_train_sub, X_test_sub, y_test_sub, k=3)\n",
    "    print(f\"Accuracy with k=3 (train): {acc_train:.4f}\")\n",
    "    print(f\"Accuracy with k=3 (test): {acc_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007b93be-8218-41df-94c7-da7b2d8e3d76",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "**Expected results**:\n",
    "```\n",
    "Accuracy with k=3 (train): 0.9755\n",
    "Accuracy with k=3 (test): 0.9190\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519802fc-d7f3-4d9e-af36-70c841864d54",
   "metadata": {},
   "source": [
    "### 4.2 **Task 4:** Try different **k** and select the best one - 1 point\n",
    "\n",
    "**Hyperparameters Tuning**\n",
    "\n",
    "As KNN is a 'lazy' algorithm - it doesn't have 'parameters' like e.g. neural networks. But it still have hyperparameters.\n",
    "**Hyperparameters** - are some constants that we set before training started. These are **not parameters of the model, but parameters of training algorithm**.\n",
    "For KNN we have three of them:\n",
    "- `n_neighbors` - our **k**\n",
    "- `weights` - our **voting strategy** - which means that we can assign more weight of vote to closer neighbours.\n",
    "- `metric` - our **distance metric** - e.g. eucledian (l2), manhatthan (l1) or other.\n",
    "\n",
    "For the simplicity we will tune just **k** here, check the accuracy (both train and test), evaluate overfitting effect and select best value of **k**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e3d601-c739-4196-8cd3-2a2fb9312348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_k(X_train, y_train, X_test, y_test, k_values):\n",
    "    \"\"\"\n",
    "    1. Iterate over k_values.\n",
    "    2. For each k, train and evaluate the model.\n",
    "    3. Store train and test accuracies.\n",
    "    4. Plot the results (Train vs Test accuracy).\n",
    "    5. Return the best k (based on Test accuracy).\n",
    "    \"\"\"\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "        # Loop through k_values\n",
    "        # Call train_and_evaluate for each k\n",
    "        # Append scores to lists\n",
    "\n",
    "    # --- Plotting the results ---\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(k_values, train_scores, marker='o', label='Train Accuracy', linestyle='--')\n",
    "    plt.plot(k_values, test_scores, marker='o', label='Test Accuracy', linewidth=2)\n",
    "    \n",
    "    plt.title('Hyperparameter Tuning: Accuracy vs K')\n",
    "    plt.xlabel('Number of Neighbors (K)')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xticks(k_values)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Find the k with the highest test accuracy\n",
    "    best_index = np.argmax(test_scores)\n",
    "    best_k = k_values[best_index]\n",
    "    \n",
    "    return best_k\n",
    "\n",
    "# --- Execution ---\n",
    "k_list = [1, 3, 5, 7, 9, 11, 15, 20]\n",
    "\n",
    "if 'X_train_sub' in locals():\n",
    "    best_k = find_best_k(X_train_sub, y_train_sub, X_test_sub, y_test_sub, k_list)\n",
    "    print(f\"The best K based on Test Set is: {best_k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f829a17d-0061-4482-83f8-fd5ce86e58b7",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "**Expected results**:\n",
    "```\n",
    "The best K based on Test Set is: 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcc8209-9fbe-477f-9367-441f9099a7e2",
   "metadata": {},
   "source": [
    "**Analysis**\n",
    "\n",
    "- As we can see - **overfitting** effect become **smaller** as **k** **increases**.\n",
    "- But still the highest test score has **k=1**.\n",
    "- So we can select this value **if the accuracy is the main requirement to our model**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd0aaf0",
   "metadata": {},
   "source": [
    "## Part 5: Inside the Black Box (Visualizing Neighbors)\n",
    "\n",
    "Accuracy is great, but **why** did the model predict that digit?\n",
    "We can look at the actual training examples that the model \"voted\" for.\n",
    "\n",
    "What is happening here?\n",
    "1. Finding of the nearest neighbors for a test image.\n",
    "2. Plotting the query image.\n",
    "3. Plotting the neighbor images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f062273e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_neighbors(model, X_test_flat_sample, X_train_flat, y_train, n_neighbors=5):\n",
    "    \"\"\"\n",
    "    X_test_flat_sample: A single flat vector (784,)\n",
    "    X_train_flat: The training data (N, 784)\n",
    "    \"\"\"\n",
    "    # Reshape input to (1, -1) for sklearn\n",
    "    query = X_test_flat_sample.reshape(1, -1)\n",
    "\n",
    "    distances, indices = model.kneighbors(query, n_neighbors=n_neighbors)\n",
    "    neighbor_indices = indices[0]\n",
    "\n",
    "    # --- Plotting Code ---\n",
    "    fig, axes = plt.subplots(1, n_neighbors + 1, figsize=(12, 3))\n",
    "\n",
    "    # 1. Plot Query Image (Reshape back to 28x28 for visualization)\n",
    "    axes[0].imshow(X_test_flat_sample.reshape(28, 28), cmap='gray')\n",
    "    axes[0].set_title(\"Query\")\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # 2. Plot Neighbors\n",
    "    for i, idx in enumerate(neighbor_indices):\n",
    "        neighbor_img_flat = X_train_flat[idx]\n",
    "        neighbor_label = y_train[idx]\n",
    "     \n",
    "        # RESHAPE here for plotting\n",
    "        img_2d = neighbor_img_flat.reshape(28, 28)\n",
    "        \n",
    "        axes[i+1].imshow(img_2d, cmap='gray')\n",
    "        axes[i+1].set_title(f\"Neighbor {i+1}\\nLabel: {neighbor_label}\")\n",
    "        axes[i+1].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Visualize neighbors for test image #100\n",
    "if 'knn_model' in locals() and knn_model is not None:\n",
    "    test_idx = 6\n",
    "    print(f\"True Label: {y_test_sub[test_idx]}\")\n",
    "    visualize_neighbors(knn_model, X_test_sub[test_idx], X_train_sub, y_train_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4d5a46-4061-44c4-8442-1dd091cf99ea",
   "metadata": {},
   "source": [
    "As you can see - distinhuish some images may be even hard for humansðŸ˜…\n",
    "\n",
    "Let's move now to the last test and the last task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594cbccb",
   "metadata": {},
   "source": [
    "## Part 6: Breaking the Model (Robustness Test)\n",
    "\n",
    "We have high accuracy. But does the model \"understand\" the digit, or just memorize pixel positions?\n",
    "Let's perform a **Pixel Shift Test**.\n",
    "\n",
    "### Part 6.1: **Task 5:** Implement a function to shift the image by `n` pixels to the right - 1 point\n",
    "Since we are working with flat vectors in the model pipeline, your function should:\n",
    "1. Reshape flat vector to 2D (28, 28).\n",
    "2. Shift pixels (using `np.roll`).\n",
    "3. Reshape back to flat vector (784)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cc5344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_image_flat(image_flat, shift_amount):\n",
    "    \"\"\"\n",
    "    Shifts the image to the right by shift_amount pixels.\n",
    "    Input/Output are flat vectors (784,).\n",
    "    \"\"\"\n",
    "    # 1. Reshape to 28x28\n",
    "    img_2d = image_flat.reshape(28, 28)\n",
    "\n",
    "    # 2. Shift using np.roll (cyclic shift)\n",
    "    # YOUR CODE HERE\n",
    "    shifted_2d = ...\n",
    "\n",
    "    # 3. Handle wrap-around (fill exposed area with 0)\n",
    "    if shift_amount > 0:\n",
    "        shifted_2d[:, :shift_amount] = 0\n",
    "\n",
    "    # 4. Flatten back to 784\n",
    "    if shifted_2d is not None:\n",
    "        return shifted_2d.flatten()\n",
    "    return image_flat\n",
    "\n",
    "# --- Experiment ---\n",
    "if 'knn_model' in locals() and knn_model is not None:\n",
    "    idx = 100 \n",
    "    original_vec = X_test_sub[idx]\n",
    "    true_label = y_test_sub[idx]\n",
    "\n",
    "    # Shift by 4 pixels\n",
    "    shift_val = 4\n",
    "    shifted_vec = shift_image_flat(original_vec, shift_val)\n",
    "\n",
    "    # Predict\n",
    "    pred_original = knn_model.predict(original_vec.reshape(1, -1))[0]\n",
    "    pred_shifted = knn_model.predict(shifted_vec.reshape(1, -1))[0]\n",
    "\n",
    "    # Visualize\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "    ax[0].imshow(original_vec.reshape(28, 28), cmap='gray')\n",
    "    ax[0].set_title(f\"Original\\nPred: {pred_original}\")\n",
    "\n",
    "    ax[1].imshow(shifted_vec.reshape(28, 28), cmap='gray')\n",
    "    ax[1].set_title(f\"Shifted ({shift_val}px)\\nPred: {pred_shifted}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eb2189-1ca4-483d-b14a-43ba477efcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nearest neighbours for original image\n",
    "visualize_neighbors(knn_model, original_vec, X_train_sub, y_train_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596e7b66-dc2b-43eb-aba2-3d9c21ad0cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nearest neighbours for shifted by 4 pixels image\n",
    "visualize_neighbors(knn_model, shifted_vec, X_train_sub, y_train_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee97aa9-58b4-4445-be36-0560d4586c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Combine data: Subset of train + Shifted + Original\n",
    "# We use a subset of X_train for speed (e.g., 5000 samples)\n",
    "subset_size = 5000\n",
    "X_subset = X_train[:subset_size]\n",
    "y_subset = y_train[:subset_size]\n",
    "\n",
    "# Stack the shifted and original vectors at the end\n",
    "X_with_examples = np.vstack([\n",
    "    X_subset, \n",
    "    shifted_vec.reshape(1, -1), \n",
    "    original_vec.reshape(1, -1)\n",
    "])\n",
    "\n",
    "# 2. Run UMAP\n",
    "print(\"Running UMAP on combined data...\")\n",
    "reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)\n",
    "embedding = reducer.fit_transform(X_with_examples)\n",
    "\n",
    "# 3. Separate the coordinates\n",
    "# The background points (training data)\n",
    "embedding_background = embedding[:subset_size]\n",
    "\n",
    "# The last two points are our specific examples\n",
    "# Index -2 is shifted_vec, Index -1 is original_vec\n",
    "embedding_shifted = embedding[-2]\n",
    "embedding_original = embedding[-1]\n",
    "\n",
    "# 4. Plotting\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# A) Plot the background training data\n",
    "scatter = plt.scatter(\n",
    "    embedding_background[:, 0], \n",
    "    embedding_background[:, 1], \n",
    "    c=y_subset, \n",
    "    cmap='Spectral', \n",
    "    s=5, \n",
    "    label='Training Data'\n",
    ")\n",
    "\n",
    "# B) Plot the Original Point (Start)\n",
    "plt.scatter(\n",
    "    embedding_original[0], \n",
    "    embedding_original[1], \n",
    "    c='black', \n",
    "    cmap='Spectral', \n",
    "    s=200, \n",
    "    marker='*', \n",
    "    edgecolors='white', \n",
    "    label=f'Original (Label: {true_label})',\n",
    "    zorder=14 # Draw on top\n",
    ")\n",
    "\n",
    "# C) Plot the Shifted Point (End)\n",
    "plt.scatter(\n",
    "    embedding_shifted[0], \n",
    "    embedding_shifted[1], \n",
    "    c='red', \n",
    "    s=200, \n",
    "    marker='X', \n",
    "    edgecolors='white', \n",
    "    label='Shifted Image',\n",
    "    zorder=10\n",
    ")\n",
    "\n",
    "# D) Draw the Shift Vector (Arrow)\n",
    "plt.arrow(\n",
    "    embedding_original[0], embedding_original[1],      # Start (x, y)\n",
    "    embedding_shifted[0] - embedding_original[0],      # dx\n",
    "    embedding_shifted[1] - embedding_original[1],      # dy\n",
    "    color='black', \n",
    "    width=0.05,            # Adjust width based on scale of UMAP\n",
    "    head_width=0.2,         # Adjust head width\n",
    "    length_includes_head=True,\n",
    "    zorder=9\n",
    ")\n",
    "\n",
    "plt.title('UMAP Projection: Visualizing the Impact of Pixel Shift', fontsize=16)\n",
    "plt.colorbar(scatter, boundaries=np.arange(11)-0.5).set_ticks(np.arange(10))\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59608164",
   "metadata": {},
   "source": [
    "### ðŸ¤” Questions to think about\n",
    "**Why did the model fail (or get low confidence) just by moving pixels?**\n",
    "\n",
    "ðŸ—“ You'll learn about it more during next week."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
